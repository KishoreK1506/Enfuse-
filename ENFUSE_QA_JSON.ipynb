{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wikipedia==1.4.0 in c:\\users\\sudharsan ramesh\\anaconda3\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\sudharsan ramesh\\anaconda3\\lib\\site-packages (from wikipedia==1.4.0) (2.22.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\sudharsan ramesh\\anaconda3\\lib\\site-packages (from wikipedia==1.4.0) (4.8.2)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\sudharsan ramesh\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia==1.4.0) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\sudharsan ramesh\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia==1.4.0) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sudharsan ramesh\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia==1.4.0) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\sudharsan ramesh\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia==1.4.0) (3.0.4)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\sudharsan ramesh\\anaconda3\\lib\\site-packages (from beautifulsoup4->wikipedia==1.4.0) (1.9.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn==1.0.2 in c:\\users\\sudharsan ramesh\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\sudharsan ramesh\\anaconda3\\lib\\site-packages (from scikit-learn==1.0.2) (1.21.6)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\sudharsan ramesh\\anaconda3\\lib\\site-packages (from scikit-learn==1.0.2) (0.14.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\sudharsan ramesh\\anaconda3\\lib\\site-packages (from scikit-learn==1.0.2) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sudharsan ramesh\\anaconda3\\lib\\site-packages (from scikit-learn==1.0.2) (3.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim==4.0.1 in c:\\users\\sudharsan ramesh\\anaconda3\\lib\\site-packages (4.0.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\sudharsan ramesh\\anaconda3\\lib\\site-packages (from gensim==4.0.1) (1.21.6)\n",
      "Requirement already satisfied: Cython==0.29.21 in c:\\users\\sudharsan ramesh\\anaconda3\\lib\\site-packages (from gensim==4.0.1) (0.29.21)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\sudharsan ramesh\\anaconda3\\lib\\site-packages (from gensim==4.0.1) (1.4.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\sudharsan ramesh\\anaconda3\\lib\\site-packages (from gensim==4.0.1) (6.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n"
     ]
    }
   ],
   "source": [
    "!pip install wikipedia==1.4.0\n",
    "!pip install scikit-learn==1.0.2\n",
    "!pip install gensim==4.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is global warming?\n",
      "Answers:  ['Climate change', 'Global warming (disambiguation)', 'Effects of climate change', 'Climate change denial']\n"
     ]
    }
   ],
   "source": [
    "import wikipedia as wiki\n",
    "\n",
    "k = 4\n",
    "question = \"What is global warming?\"\n",
    "\n",
    "results = wiki.search(question, results=k)\n",
    "print('Question:', question)\n",
    "print('Answers: ', results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "In this section, we are going to load a json file into a pandas.DataFrame. At last, elaborate our list of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/Semester 2/ENFUSE/pdf_data/dev-v1.1.json\n",
      "D:/Semester 2/ENFUSE/pdf_data/train-v1.1.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# list the available data\n",
    "for dirname, _, filenames in os.walk('D:/Semester 2/ENFUSE/pdf_data/'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squad_json_to_dataframe(file_path, record_path=['data','paragraphs','qas','answers']):\n",
    "    \"\"\"\n",
    "    input_file_path: path to the squad json file.\n",
    "    record_path: path to deepest level in json file default value is\n",
    "    ['data','paragraphs','qas','answers']\n",
    "    \"\"\"\n",
    "    file = json.loads(open(file_path).read())\n",
    "    # parsing different level's in the json file\n",
    "    js = pd.json_normalize(file, record_path)\n",
    "    m = pd.json_normalize(file, record_path[:-1])\n",
    "    r = pd.json_normalize(file,record_path[:-2])\n",
    "    # combining it into single dataframe\n",
    "    idx = np.repeat(r['context'].values, r.qas.str.len())\n",
    "    m['context'] = idx\n",
    "    data = m[['id','question','context','answers']].set_index('id').reset_index()\n",
    "    data['c_id'] = data['context'].factorize()[0]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answers</th>\n",
       "      <th>c_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>[{'answer_start': 515, 'text': 'Saint Bernadet...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5733be284776f4190066117f</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>[{'answer_start': 188, 'text': 'a copper statu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5733be284776f41900661180</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>[{'answer_start': 279, 'text': 'the Main Build...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5733be284776f41900661181</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>[{'answer_start': 381, 'text': 'a Marian place...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5733be284776f4190066117e</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>[{'answer_start': 92, 'text': 'a golden statue...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87594</th>\n",
       "      <td>5735d259012e2f140011a09d</td>\n",
       "      <td>In what US state did Kathmandu first establish...</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>[{'answer_start': 229, 'text': 'Oregon'}]</td>\n",
       "      <td>18890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87595</th>\n",
       "      <td>5735d259012e2f140011a09e</td>\n",
       "      <td>What was Yangon previously known as?</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>[{'answer_start': 414, 'text': 'Rangoon'}]</td>\n",
       "      <td>18890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87596</th>\n",
       "      <td>5735d259012e2f140011a09f</td>\n",
       "      <td>With what Belorussian city does Kathmandu have...</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>[{'answer_start': 476, 'text': 'Minsk'}]</td>\n",
       "      <td>18890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87597</th>\n",
       "      <td>5735d259012e2f140011a0a0</td>\n",
       "      <td>In what year did Kathmandu create its initial ...</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>[{'answer_start': 199, 'text': '1975'}]</td>\n",
       "      <td>18890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87598</th>\n",
       "      <td>5735d259012e2f140011a0a1</td>\n",
       "      <td>What is KMC an initialism of?</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>[{'answer_start': 0, 'text': 'Kathmandu Metrop...</td>\n",
       "      <td>18890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87599 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id  \\\n",
       "0      5733be284776f41900661182   \n",
       "1      5733be284776f4190066117f   \n",
       "2      5733be284776f41900661180   \n",
       "3      5733be284776f41900661181   \n",
       "4      5733be284776f4190066117e   \n",
       "...                         ...   \n",
       "87594  5735d259012e2f140011a09d   \n",
       "87595  5735d259012e2f140011a09e   \n",
       "87596  5735d259012e2f140011a09f   \n",
       "87597  5735d259012e2f140011a0a0   \n",
       "87598  5735d259012e2f140011a0a1   \n",
       "\n",
       "                                                question  \\\n",
       "0      To whom did the Virgin Mary allegedly appear i...   \n",
       "1      What is in front of the Notre Dame Main Building?   \n",
       "2      The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                      What is the Grotto at Notre Dame?   \n",
       "4      What sits on top of the Main Building at Notre...   \n",
       "...                                                  ...   \n",
       "87594  In what US state did Kathmandu first establish...   \n",
       "87595               What was Yangon previously known as?   \n",
       "87596  With what Belorussian city does Kathmandu have...   \n",
       "87597  In what year did Kathmandu create its initial ...   \n",
       "87598                      What is KMC an initialism of?   \n",
       "\n",
       "                                                 context  \\\n",
       "0      Architecturally, the school has a Catholic cha...   \n",
       "1      Architecturally, the school has a Catholic cha...   \n",
       "2      Architecturally, the school has a Catholic cha...   \n",
       "3      Architecturally, the school has a Catholic cha...   \n",
       "4      Architecturally, the school has a Catholic cha...   \n",
       "...                                                  ...   \n",
       "87594  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87595  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87596  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87597  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87598  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "\n",
       "                                                 answers   c_id  \n",
       "0      [{'answer_start': 515, 'text': 'Saint Bernadet...      0  \n",
       "1      [{'answer_start': 188, 'text': 'a copper statu...      0  \n",
       "2      [{'answer_start': 279, 'text': 'the Main Build...      0  \n",
       "3      [{'answer_start': 381, 'text': 'a Marian place...      0  \n",
       "4      [{'answer_start': 92, 'text': 'a golden statue...      0  \n",
       "...                                                  ...    ...  \n",
       "87594          [{'answer_start': 229, 'text': 'Oregon'}]  18890  \n",
       "87595         [{'answer_start': 414, 'text': 'Rangoon'}]  18890  \n",
       "87596           [{'answer_start': 476, 'text': 'Minsk'}]  18890  \n",
       "87597            [{'answer_start': 199, 'text': '1975'}]  18890  \n",
       "87598  [{'answer_start': 0, 'text': 'Kathmandu Metrop...  18890  \n",
       "\n",
       "[87599 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the data\n",
    "file_path = 'D:/Semester 2/ENFUSE/pdf_data/train-v1.1.json'\n",
    "data = squad_json_to_dataframe(file_path)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18891"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many documents do we have?\n",
    "data['c_id'].unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Unique Documents\n",
    "\n",
    "Let's select the unique documents in our data. This will be the list of documents to search for the answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>c_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As at most other universities, Notre Dame's st...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The university is the major seat of the Congre...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The College of Engineering was established in ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All of Notre Dame's undergraduate students are...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18886</th>\n",
       "      <td>Institute of Medicine, the central college of ...</td>\n",
       "      <td>18886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18887</th>\n",
       "      <td>Football and Cricket are the most popular spor...</td>\n",
       "      <td>18887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18888</th>\n",
       "      <td>The total length of roads in Nepal is recorded...</td>\n",
       "      <td>18888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18889</th>\n",
       "      <td>The main international airport serving Kathman...</td>\n",
       "      <td>18889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18890</th>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>18890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18891 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 context   c_id\n",
       "0      Architecturally, the school has a Catholic cha...      0\n",
       "1      As at most other universities, Notre Dame's st...      1\n",
       "2      The university is the major seat of the Congre...      2\n",
       "3      The College of Engineering was established in ...      3\n",
       "4      All of Notre Dame's undergraduate students are...      4\n",
       "...                                                  ...    ...\n",
       "18886  Institute of Medicine, the central college of ...  18886\n",
       "18887  Football and Cricket are the most popular spor...  18887\n",
       "18888  The total length of roads in Nepal is recorded...  18888\n",
       "18889  The main international airport serving Kathman...  18889\n",
       "18890  Kathmandu Metropolitan City (KMC), in order to...  18890\n",
       "\n",
       "[18891 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = data[['context', 'c_id']].drop_duplicates().reset_index(drop=True)\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# defining the TF-IDF\n",
    "tfidf_configs = {\n",
    "    'lowercase': True,\n",
    "    'analyzer': 'word',\n",
    "    'stop_words': 'english',\n",
    "    'binary': True,\n",
    "    'max_df': 0.9,\n",
    "    'max_features': 10_000\n",
    "}\n",
    "# defining the number of documents to retrieve\n",
    "retriever_configs = {\n",
    "    'n_neighbors': 10,\n",
    "    'metric': 'cosine'\n",
    "}\n",
    "\n",
    "# defining our pipeline\n",
    "embedding = TfidfVectorizer(**tfidf_configs)\n",
    "retriever = NearestNeighbors(**retriever_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(metric='cosine', n_neighbors=10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's train the model to retrieve the document id 'c_id'\n",
    "X = embedding.fit_transform(documents['context'])\n",
    "retriever.fit(X, documents['c_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the vectorizer, what information our model is using to extract the vector?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text(vectorizer, text):\n",
    "    '''\n",
    "    Print the text and the vector[TF-IDF]\n",
    "    vectorizer: sklearn.vectorizer\n",
    "    text: str\n",
    "    '''\n",
    "    print('Text:', text)\n",
    "    vector = vectorizer.transform([text])\n",
    "    vector = vectorizer.inverse_transform(vector)\n",
    "    print('Vect:', vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: What is global warming?\n",
      "Vect: [array(['warming', 'global'], dtype='<U18')]\n"
     ]
    }
   ],
   "source": [
    "# vectorize the question\n",
    "transform_text(embedding, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the most similar document to this question?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: In glaciated areas where the glacier moves faster than one km per year, glacial earthquakes occur. These are large scale temblors that have seismic magnitudes as high as 6.1. The number of glacial earthquakes in Greenland peaks every year in July, August and September and is increasing over time. In a study using data from January 1993 through October 2005, more events were detected every year since 2002, and twice as many events were recorded in 2005 as there were in any other year. This increase in the numbers of glacial earthquakes in Greenland may be a response to global warming.\n",
      "Vect: [array(['year', 'warming', 'using', 'twice', 'time', 'study', 'september',\n",
      "       'scale', 'response', 'recorded', 'peaks', 'october', 'occur',\n",
      "       'numbers', 'number', 'moves', 'large', 'km', 'july', 'january',\n",
      "       'increasing', 'increase', 'high', 'greenland', 'global', 'glacier',\n",
      "       'glacial', 'faster', 'events', 'earthquakes', 'detected', 'data',\n",
      "       'august', 'areas', '2005', '2002', '1993'], dtype='<U18')]\n"
     ]
    }
   ],
   "source": [
    "# predict the most similar document\n",
    "X = embedding.transform([question])\n",
    "c_id = retriever.kneighbors(X, return_distance=False)[0][0]\n",
    "selected = documents.iloc[c_id]['context']\n",
    "\n",
    "# vectorize the document\n",
    "transform_text(embedding, selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# predict one document for each question\n",
    "X = embedding.transform(data['question'])\n",
    "y_test = data['c_id']\n",
    "y_pred = retriever.kneighbors(X, return_distance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,  3694, 10613, ..., 17590,  6913,  6912],\n",
       "       [    7,  1469,     2, ...,    29, 14201,    17],\n",
       "       [   38,  1469, 14152, ...,    28,     7, 14201],\n",
       "       ...,\n",
       "       [18890, 18884, 18836, ..., 12302, 18837,  4200],\n",
       "       [18890,  3537, 18841, ..., 16014, 18884, 10882],\n",
       "       [12592, 12591, 12598, ..., 12593, 12600, 12588]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top documents predicted for each question\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_accuracy(y_true, y_pred) -> float:\n",
    "    right, count = 0, 0\n",
    "    for i, y_t in enumerate(y_true):\n",
    "        count += 1\n",
    "        if y_t in y_pred[i]:\n",
    "            right += 1\n",
    "    return right / count if count > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7148\n",
      "Quantity: 62615 from 87599\n"
     ]
    }
   ],
   "source": [
    "acc = top_accuracy(y_test, y_pred)\n",
    "print('Accuracy:', f'{acc:.4f}')\n",
    "print('Quantity:', int(acc*len(y_pred)), 'from', len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudharsan Ramesh\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "\n",
    "# create a corpus of tokens\n",
    "corpus = documents['context'].tolist()\n",
    "corpus = [preprocess_string(t) for t in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader\n",
    "\n",
    "# you can download a pretrained Word2Vec\n",
    "# - or you can train your own model\n",
    "\n",
    "# download a model\n",
    "# 'glove-wiki-gigaword-300' (376.1 MB)\n",
    "# 'word2vec-ruscorpora-300' (198.8 MB)\n",
    "# 'word2vec-google-news-300' (1.6 GB)\n",
    "# vectorizer = gensim.downloader.load('word2vec-ruscorpora-300')\n",
    "\n",
    "# train your own model\n",
    "vectorizer = Word2Vec(sentences=corpus, vector_size=300, window=5, min_count=1, workers=4).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar words to 'nlp'\n",
    "#vectorizer.most_similar('nlp', topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text2(vectorizer, text, verbose=False):\n",
    "    '''\n",
    "    Transform the text in a vector[Word2Vec]\n",
    "    vectorizer: sklearn.vectorizer\n",
    "    text: str\n",
    "    '''\n",
    "    tokens = preprocess_string(text)\n",
    "    words = [vectorizer[w] for w in tokens if w in vectorizer]\n",
    "    if verbose:\n",
    "        print('Text:', text)\n",
    "        print('Vector:', [w for w in tokens if w in vectorizer])\n",
    "    elif len(words):\n",
    "        return np.mean(words, axis=0)\n",
    "    else:\n",
    "        return np.zeros((300), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: What is global warming?\n",
      "Vector: ['global', 'warm']\n"
     ]
    }
   ],
   "source": [
    "# just testing our Word2Vec\n",
    "transform_text2(vectorizer, question, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(metric='cosine', n_neighbors=10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's train the model to retrieve the document id 'c_id'\n",
    "retriever2 = NearestNeighbors(**retriever_configs)\n",
    "\n",
    "# vectorizer the documents, fit the retriever\n",
    "X = documents['context'].apply(lambda x: transform_text2(vectorizer, x)).tolist()\n",
    "retriever2.fit(X, documents['c_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
